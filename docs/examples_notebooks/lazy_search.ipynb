{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fefad3a",
   "metadata": {},
   "source": [
    "# LazyGraphRAG Search Example\n",
    "\n",
    "LazyGraphRAG is a cost-efficient alternative to full GraphRAG that achieves comparable quality at approximately **1/100th of the cost**. It uses iterative deepening search with budget-controlled LLM calls.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Budget-controlled LLM calls**: Z100/Z500/Z1500 presets for cost management\n",
    "- **Iterative deepening search**: Progressive exploration focused on relevant content\n",
    "- **Query expansion**: Subquery decomposition for comprehensive coverage\n",
    "- **Claim extraction**: Structured fact extraction from relevant content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b62e73",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and load the indexed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84003c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from graphrag.config.enums import ModelType\n",
    "from graphrag.config.models.language_model_config import LanguageModelConfig\n",
    "from graphrag.config.models.lazy_search_config import LazySearchConfig\n",
    "from graphrag.language_model.manager import ModelManager\n",
    "from graphrag.query.indexer_adapters import read_indexer_text_units\n",
    "from graphrag.query.structured_search.lazy_search import (\n",
    "    LazySearch,\n",
    "    LazySearchData,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af822f",
   "metadata": {},
   "source": [
    "## Load Indexed Data\n",
    "\n",
    "LazyGraphRAG primarily uses text chunks from the indexing pipeline. Unlike Local or Global search, it doesn't require the full knowledge graph - just the text units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bfc95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"./inputs/operation dulce\"\n",
    "TEXT_UNIT_TABLE = \"text_units\"\n",
    "\n",
    "# Read text units\n",
    "text_unit_df = pd.read_parquet(f\"{INPUT_DIR}/{TEXT_UNIT_TABLE}.parquet\")\n",
    "\n",
    "print(f\"Text unit count: {len(text_unit_df)}\")\n",
    "text_unit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c3a63",
   "metadata": {},
   "source": [
    "## Initialize Chat Model\n",
    "\n",
    "LazyGraphRAG uses an LLM for query expansion, relevance testing, and response generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d541f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get(\"GRAPHRAG_API_KEY\", \"\")\n",
    "\n",
    "chat_config = LanguageModelConfig(\n",
    "    api_key=api_key,\n",
    "    type=ModelType.Chat,\n",
    "    model_provider=\"openai\",\n",
    "    model=\"gpt-4.1\",\n",
    "    max_retries=20,\n",
    ")\n",
    "\n",
    "chat_model = ModelManager().get_or_create_chat_model(\n",
    "    name=\"lazy_search\",\n",
    "    model_type=ModelType.Chat,\n",
    "    config=chat_config,\n",
    ")\n",
    "\n",
    "print(f\"Chat model initialized: {chat_config.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22afbde9",
   "metadata": {},
   "source": [
    "## Prepare Search Data\n",
    "\n",
    "Create the data container for LazySearch. The text chunks need to have `id` and `text` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare text chunks for LazySearch\n",
    "text_chunks = text_unit_df[[\"id\", \"text\"]].copy()\n",
    "\n",
    "# Add community_id if available from the dataframe, otherwise use default\n",
    "if \"community_id\" in text_unit_df.columns:\n",
    "    text_chunks[\"community_id\"] = text_unit_df[\"community_id\"]\n",
    "else:\n",
    "    text_chunks[\"community_id\"] = \"default\"\n",
    "\n",
    "# Create LazySearchData\n",
    "search_data = LazySearchData(text_chunks=text_chunks)\n",
    "\n",
    "print(f\"Prepared {len(text_chunks)} text chunks for search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a3bb6e",
   "metadata": {},
   "source": [
    "## Configure LazySearch\n",
    "\n",
    "LazyGraphRAG provides three presets for different cost/quality tradeoffs:\n",
    "\n",
    "| Preset | Budget | Use Case |\n",
    "|--------|--------|----------|\n",
    "| `z100` | 100 | Quick, low-cost queries |\n",
    "| `z500` | 500 | Balanced (default) |\n",
    "| `z1500` | 1500 | High-quality, thorough search |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdcdbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Z500 preset (balanced)\n",
    "config = LazySearchConfig.from_preset(\"z500\")\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Relevance budget: {config.relevance_budget}\")\n",
    "print(f\"  Top-k chunks: {config.top_k_chunks}\")\n",
    "print(f\"  Relevance threshold: {config.relevance_threshold}\")\n",
    "print(f\"  Max depth: {config.max_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238cd62e",
   "metadata": {},
   "source": [
    "## Create LazySearch Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70689b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = LazySearch(\n",
    "    model=chat_model,\n",
    "    config=config,\n",
    "    data=search_data,\n",
    ")\n",
    "\n",
    "print(\"LazySearch instance created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d384dab",
   "metadata": {},
   "source": [
    "## Run a Search Query\n",
    "\n",
    "Let's run a sample query and examine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the main themes and events described in the documents?\"\n",
    "\n",
    "result = await search.search(query)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RESPONSE\")\n",
    "print(\"=\" * 80)\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afb4d57",
   "metadata": {},
   "source": [
    "## Examine Search Metrics\n",
    "\n",
    "LazySearch provides detailed metrics about the search process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e88dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Search Metrics:\")\n",
    "print(f\"  Completion time: {result.completion_time:.2f}s\")\n",
    "print(f\"  Iterations used: {result.iterations_used}\")\n",
    "print(f\"  Chunks processed: {result.chunks_processed}\")\n",
    "print(f\"  Budget used: {result.budget_used}\")\n",
    "print(f\"  Claims extracted: {result.claims_extracted}\")\n",
    "print(f\"  Relevant sentences: {result.relevant_sentences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d6cd42",
   "metadata": {},
   "source": [
    "## Using Different Presets\n",
    "\n",
    "Let's compare results with different budget presets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ffcc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z100 - Low budget, faster\n",
    "config_z100 = LazySearchConfig.from_preset(\"z100\")\n",
    "search_z100 = LazySearch(model=chat_model, config=config_z100, data=search_data)\n",
    "\n",
    "result_z100 = await search_z100.search(\"What is the main conflict in the story?\")\n",
    "\n",
    "print(\"Z100 Results:\")\n",
    "print(f\"  Time: {result_z100.completion_time:.2f}s\")\n",
    "print(f\"  Budget used: {result_z100.budget_used}\")\n",
    "print(f\"  Response length: {len(result_z100.response)} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f617e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z1500 - High budget, more thorough\n",
    "config_z1500 = LazySearchConfig.from_preset(\"z1500\")\n",
    "search_z1500 = LazySearch(model=chat_model, config=config_z1500, data=search_data)\n",
    "\n",
    "result_z1500 = await search_z1500.search(\"What is the main conflict in the story?\")\n",
    "\n",
    "print(\"Z1500 Results:\")\n",
    "print(f\"  Time: {result_z1500.completion_time:.2f}s\")\n",
    "print(f\"  Budget used: {result_z1500.budget_used}\")\n",
    "print(f\"  Response length: {len(result_z1500.response)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511de2b",
   "metadata": {},
   "source": [
    "## Custom Configuration\n",
    "\n",
    "You can also create custom configurations for fine-tuned control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1087bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_config = LazySearchConfig(\n",
    "    relevance_budget=300,\n",
    "    relevance_threshold=6.0,  # Higher threshold = stricter filtering\n",
    "    max_depth=2,\n",
    "    sufficient_relevance_count=30,\n",
    "    include_citations=True,\n",
    ")\n",
    "\n",
    "search_custom = LazySearch(\n",
    "    model=chat_model,\n",
    "    config=custom_config,\n",
    "    data=search_data,\n",
    ")\n",
    "\n",
    "result_custom = await search_custom.search(\"Who are the key characters?\")\n",
    "\n",
    "print(\"Custom Config Results:\")\n",
    "print(f\"  Time: {result_custom.completion_time:.2f}s\")\n",
    "print(f\"  Budget used: {result_custom.budget_used}\")\n",
    "print(\"\\nResponse:\")\n",
    "print(result_custom.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093b4768",
   "metadata": {},
   "source": [
    "## Using from_preset Factory Method\n",
    "\n",
    "For convenience, you can use the `from_preset` factory method to create a LazySearch instance directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc755082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick setup using from_preset\n",
    "quick_search = LazySearch.from_preset(\n",
    "    preset=\"z500\",\n",
    "    model=chat_model,\n",
    "    data=search_data,\n",
    ")\n",
    "\n",
    "result = await quick_search.search(\"Summarize the key events.\")\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0a23e3",
   "metadata": {},
   "source": [
    "## Accessing Context Data\n",
    "\n",
    "The search result includes detailed context data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26da14ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access context data\n",
    "if result.context_data:\n",
    "    print(\"Context data keys:\", list(result.context_data.keys()))\n",
    "    \n",
    "    # Show claims if available\n",
    "    if \"claims\" in result.context_data:\n",
    "        claims_df = result.context_data[\"claims\"]\n",
    "        print(f\"\\nExtracted claims: {len(claims_df)}\")\n",
    "        if not claims_df.empty:\n",
    "            print(claims_df[[\"statement\", \"confidence\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bcd8f1",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "1. **Choose the right preset**:\n",
    "   - `z100`: Quick FAQs, simple factual questions\n",
    "   - `z500`: General questions, analysis tasks\n",
    "   - `z1500`: Complex questions, detailed analysis\n",
    "\n",
    "2. **Adjust threshold**: Higher `relevance_threshold` (6-8) for precision, lower (3-5) for recall\n",
    "\n",
    "3. **Monitor budget**: Check `budget_used` vs `relevance_budget` to understand cost\n",
    "\n",
    "4. **Use citations**: Set `include_citations=True` for traceable responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a2f426",
   "metadata": {},
   "source": [
    "## Comparison with Other Search Methods\n",
    "\n",
    "| Feature | LazySearch | GlobalSearch | LocalSearch |\n",
    "|---------|------------|--------------|-------------|\n",
    "| Cost | Low (~1/100) | High | Medium |\n",
    "| Speed | Fast | Slow | Medium |\n",
    "| Data Required | Text chunks | Community reports | Full graph |\n",
    "| Best For | General queries | Dataset summaries | Entity-specific |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
